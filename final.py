# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SdNgRbzF6GZ9R0AVRkR6ytUxNZv1KGFn
"""

#Grupo:
# Dayli Pimentel
# Abel Bellido

import pandas as pd

#1- Cargar la información del dataset y entenderlo.
dataset_url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
columns = ["pregnancies", "glucose", "blood_pressure", "skin_thickness", "insulin", "bmi", "diabetes_pedigree", "age", "target"]
df = pd.read_csv(dataset_url, names=columns)

# Visualización
df

#1- Asimismo se debe volcar la información de inputs "data" en una variable X y el output "target" en otra variable Y e indicar que tipos de datos
X = df.iloc[:, :-1].values  # X = Variables independientes (pregnancies,glucose,blood_pressure,skin_thickness,insulin,bmi,diabetes_pedigree,age)
Y = df.iloc[:, -1].values  # Y = Variable dependiente (target)

#1-Finalmente se debe guardar en una variable los nombres de las variables de estudio "feature_names" (o etiquetas).
feature_names = columns[:-1]
feature_names
# Se considera variables de estudio a todas las variables menos a target ya que este es la variable dependiente.

#2-Se debe generar el dataframe con las etiquetas y la data cargada en punto1
df_diabetes = pd.DataFrame(X, columns=feature_names)
df_diabetes

#Se generó el dataframe con la data de la variable X.

# 3-Se debe retirar del dataframe los campos age y pregnancies del dataframe
df_diabetes = df_diabetes.drop(columns=["pregnancies", "age"])
df_diabetes

# 3-Asimismo se debe revisar el tipo de dato de todas las variables (indicando si booleano, entero, float etc)
df.info()

# Se puede ver que todas las variables son enteras a excepción de las variables bmi y diabetes_pedigree ya que contienen numeros decimales.

#4-Aplicar revisión estadística de todas las variables aplicando describe() y comentar los hallazgos como lo revisado en clase
df.describe()

#Pregnancies: La media es 3.84, con un valor máximo de 17.
#Glucose: La media es de 120.89, con valores desde 0 (posiblemente faltantes) hasta 199, lo que indica una distribución amplia.
#Blood Pressure: La media es de de 69.1, con un mínimo de 0, lo que indica qur hay valores nulos.
#Skin Thickness: La media es de de 20.53 y un máximo de 99, y un mínimo de 0 que indica valores nulos.
#Insulin: La media es de de 79.79 y tiene valores extremos hasta 846. Se deben analizar outliers.
#BMI: La media es de de 31.99, con valores desde 0 hasta 67.1. El valor 0 no es realista.
#Diabetes Pedigree: La media es de de 0.47, pero el máximo es 2.42, indicando posible sesgo en algunos casos.
#Age: La media es de de 33.24, con valores hasta 81.
#Target: La media es de 0.3489, lo que indica que el 35% de los pacientes tienen diabetes.

#5- Se debe revisar si existe datos nulos en las variables y/o campos del dataframe.
df_diabetes.isnull().sum()

# Existen datos nulos para las variables glucose, blood_pressure, skin_thickness, insulin y bmi.

# 6-Agregar el "target" al data frame a un campo llamado "diagnostico"
target=df["target"]
df_diabetes["diagnostico"] = target
df_diabetes

# 7-Contar casos de diagnóstico de diabetes y sin diabetes existe y
#este resultado graficarlo en un grafico de barras para compararlos.
data_eval=pd.DataFrame(df_diabetes["diagnostico"].value_counts())
data_eval = data_eval.rename(index={0: "Sin Diabetes", 1: "Con Diabetes"})
data_eval.reset_index(inplace=True)
data_eval.columns = ["Diagnóstico", "Cantidad"]
data_eval

#7-Grafico de barras comparativo
import matplotlib.pyplot as plt

plt.figure(figsize=(6, 4))
plt.bar(data_eval["Diagnóstico"], data_eval["Cantidad"], color=['blue', 'orange'])
plt.xlabel("Diagnóstico")
plt.ylabel("Cantidad de Casos")
plt.title("Cantidad de casos de diabetes")
plt.show()

#8-Realizar un boxplot de todas las variables.
import seaborn as sns

fig, axs = plt.subplots(2, 4, figsize=(15, 10))
plt.suptitle("ANÁLISIS DE VALORES ATÍPICOS", size=18)
sns.boxplot(y=df_diabetes["glucose"], orient="v", ax=axs[0,0], color="steelblue")
sns.boxplot(y=df_diabetes["blood_pressure"], orient ="v", ax=axs[0,1], color="lightseagreen")
sns.boxplot(y=df_diabetes["skin_thickness"], orient="v", ax=axs[0,2], color="red")
sns.boxplot(y=df_diabetes["insulin"], orient ="v", ax=axs[0,3], color="yellow")
sns.boxplot(y=df_diabetes["bmi"], orient ="v", ax=axs[1,0], color="forestgreen")
sns.boxplot(y=df_diabetes["diabetes_pedigree"], orient ="v", ax=axs[1,1], color="purple")
fig.subplots_adjust(wspace=0.5, hspace=0.5)
plt.show()

#9-Encontrar cuales son las variables menos importantes y mencionarlas pero no retirarlas.Solo aplicar correlacion para el análisis.
fig, ax = plt.subplots(figsize=(17,12))
df_diabetes.corr()["diagnostico"].sort_values(ascending=True).plot(kind="bar",cmap="rainbow",alpha=0.7)
plt.title("ANALISIS DE CORRELACION")
for i in['bottom','left']:
    ax.spines[i].set_color('black')
    ax.spines[i].set_linewidth(1.5)
right_side = ax.spines["right"]
right_side.set_visible(False)
top_side = ax.spines["top"]
top_side.set_visible(False)
ax.set_axisbelow(True)
ax.grid(color='gray',linewidth=1,axis='y',alpha=0.4)
plt.show()

#Al revisar el coeficiente de Pearson se identificó  que las variables menos importantes son blood_pressure y skin_thickness ya que se
# encuentren entre los intervalos 0 y 0.1.
# Ademas al revisar la correlación entre las variable diagnostico, blood_pressure y skin_thickness se observa que la correlaciòn es la sigueinte:
#  blood_pressure - diagnostico: 0.065068
# skin_thickness - diagnostico: 0.074752
print(df_diabetes.corr(numeric_only=True))

#10-Aplicar entrenamiento y predicción a los  modelo LogisticRegression y SVC
#11- Presentar el resultado del scores de la predicción y matriz de confusión , luego comentar resultados

#a.Entrenamiento
#Variables
X= df_diabetes.drop("diagnostico",axis=1)
y=df_diabetes["diagnostico"].values

#b.Variables para entrenamiento y prueba
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=7, shuffle=True)

#c.Llamado a la libreria
from sklearn.linear_model import LogisticRegression
model= LogisticRegression()
result= model.fit(X_train,y_train)

#d.Validación con 3 parametros
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score

target_pred=model.predict(X_test)

print(f'Recall Score(Falsos Negativos) :{recall_score(y_test,target_pred)}')
print(f'Accuracy Score(Fraccion que modelo realizó correcto) :{accuracy_score(y_test,target_pred)}')
print(f'Precision Score(Falsos Positivos) :{precision_score(y_test,target_pred)}')

# Predicción del modelo LogisticRegression con la función Accuracy
def val_accuracy(d_test,y_predict):

    accuracy=[]
    true_value=d_test
    predictions=y_predict
    cont_true_val=0

    #Conteo
    for i in range(len(true_value)):
        if true_value[i] == predictions[i]:
            cont_true_val = cont_true_val + 1
    #Calculo porcentaje
    result=cont_true_val/float(len(true_value))*100.0
    accuracy.append(result)
    #Accuracy
    print('Accuracy: %.3f%%' % (sum(accuracy)/float(len(accuracy))))
#Obtenemos Accuracy
val_accuracy(y_test,target_pred)

# Con el modelo LogisticRegression se obtuvo una precisón de 77.922%

# Matriz de confusión

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

target_names=['Sin Diabetes','Con Diabetes']
cm=confusion_matrix(y_test, target_pred, labels=model.classes_,normalize='true')
display=ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)
display=display.plot(cmap=plt.cm.Blues)
plt.show()

# El 90% de los casos fueron correctamente clasificados como " Sin diabetes" y el 58% de los casos como "Con diabetes"
# Además,, presenta un 10% de error en la predicción de diabetes, 10% los casos fueron clasificados incorrectamente como casos con "Con diabetes"
# Asimismo, 42% son casos "Con diabetes" que el modelo no detectó.

# Predicción del modelo SVM con la función Accuracy
from sklearn import svm

model_2=svm.SVC()

result=model_2.fit(X_train, y_train)

target_pred_2 = model.predict(X_test)
print(f'Recall Score (Falsos Negativos) :{recall_score(y_test,target_pred_2)}')
print(f'Accuracy Score (Fraccion que modelo realizó correct. ) :{accuracy_score(y_test,target_pred_2)}')
print(f'Precision Score (Falsos Positivos) :{precision_score(y_test,target_pred_2)}')

# Llamado a la función Accuracy
val_accuracy(y_test,target_pred_2)

# Con el modelo SVM también se obtuvo una precisón de 77.922%

# Matriz de confusión
target_names=['Sin Diabetes','Con Diabetes']
cm=confusion_matrix(y_test, target_pred_2, labels=model_2.classes_,normalize='true')
display=ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)
display=display.plot(cmap=plt.cm.Greens)
plt.show()

#La matriz de confusión para el modelo SVM da los mismo resultados que el modelo LogisticRegression.

# Se concluye :
# Precisión del modelo LogisticRegression: 77.922%
# Precisión del modelo SVM: 77.922%
# Al ser el resultado de los dos modelos iguales, se podrian utilizar cualquiera de los dos para realizar predicciones.
# Sin embargo, dado que se quiere predecir a partir de datos estructurados se utilizaría el modelo de Logistic Regression.